{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "- `titles:` list of titles of songs.\n",
    "- `data:` list of dictionary contains title and path of songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('Data\\Billboard.csv')\n",
    "print(dataset.shape)\n",
    "titles = list(dataset['Title'])\n",
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search method\n",
    "- Use os to move songs into directory(Songs for popular data and Unpopular for unpoular data) contains all songs we saved it as mp3 files.\n",
    "- Use requests to get songs from youtube.\n",
    "- Use yt_dlp instead of youtube_dl to download songs because it faster than youtube_dl.\n",
    "\n",
    "*`Parametres: `*\n",
    "- `YDL_OPTIONS:` with format: 'bestaudio' to download best audio quality and noplaylist:True to avoid download playlists.\n",
    "- `YoutubeDL(YDL_OPTIONS) as ydl:` download songs.\n",
    "- `song:` this is a first song we get from youtube searching.\n",
    "- `oldpath:` name of song.\n",
    "- `newpath:` this is a path we want to move song into.\n",
    "- `type:` to see if songs is poular or not.\n",
    "\n",
    "    At the end we return song and path to save it in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from requests import get\n",
    "# from youtube_dl import YoutubeDL (It take alot of time to download songs)\n",
    "from yt_dlp import YoutubeDL # (It take no time)\n",
    "\n",
    "YDL_OPTIONS = {'format': 'bestaudio', 'noplaylist':'True'}\n",
    "\n",
    "def search(arg, type):\n",
    "    with YoutubeDL(YDL_OPTIONS) as ydl:\n",
    "        try:\n",
    "            get(arg) \n",
    "        except:\n",
    "            song = ydl.extract_info(f\"ytsearch:{arg}\", download=True)['entries'][0]\n",
    "        else:\n",
    "            song = ydl.extract_info(arg, download=True)\n",
    "    \n",
    "    oldpath = song['title'] + ' [' + song['id'] + '].' + song['ext']\n",
    "    newpath = f\"{type}/{song['title']}.mp3\"\n",
    "    os.rename(f\"{oldpath}\", newpath)\n",
    "\n",
    "    return song, newpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error would be happen\n",
    "- *If error is 403:* you must update i with last value of i and run this cell again.\n",
    "- *Path doesn't exist:* go to name of this song and rename it with .mp3 finally move it to his directory and update data with new dict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now download all songs\n",
    "    search for song by title and name of artist to avoid downloaded another title from youtube.\n",
    "*Parameters*\n",
    "- `i:` iterator for looping in every title in titles.\n",
    "- `string:` title of song and name of artist to search with it to avoid download anything else song.\n",
    "- in search method when i from 0 to 380 is popular(Songs) and from 381 to 785 is unpopular(Unpopuplar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(titles):\n",
    "    string = titles[i] + ' ' + dataset['Artist'][dataset['Title'] == titles[i]].values[0]\n",
    "    if i < 381:\n",
    "        audio, path = search(string, 'Songs') # Songs directory to collect all popular songs.\n",
    "    else:\n",
    "        audio, path = search(string, 'Unpopular') # Unpopular directory to collect all unpopular songs.\n",
    "\n",
    "    data.append({'Title': titles[i], 'Path': path})\n",
    "    i += 1\n",
    "    if i == len(titles):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = pd.read_csv('NewData.csv')\n",
    "for row in data:\n",
    "    newData = newData.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData.to_csv('Data\\NewData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now add this newData to orgnial dataset as a columns and name it with DataWithMusic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path column\n",
    "dataset['Path'] = newData['Path']\n",
    "# Add title column with Title column in newData to check data\n",
    "dataset['title'] = newData['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtitles = list(dataset['title'])  # to collect titles which we added\n",
    "titles = list(dataset['Title'])     # to coolect old Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lostdata = []  # list to Titles and titles with doesn't matches\n",
    "i = 0\n",
    "for i in range(len(titles)):\n",
    "    if titles[i] != newtitles[i]:\n",
    "        lostdata.append({'Title':titles[i],'title':newtitles[i]})\n",
    "    i+=1\n",
    "\n",
    "# to see if any lost data or not. if(just delete rows) else dataset is good\n",
    "print(len(lostdata))\n",
    "lostdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I found this data was lost so I dropped it.\n",
    "'''\n",
    "first = dataset[dataset['Title']=='Can\\'t Stop The Feeling!']\n",
    "second = dataset[dataset['Title']=='Heathens']\n",
    "third = dataset[dataset['title']=='How Do You Sleep?']\n",
    "print(first)\n",
    "print(second)\n",
    "print(third)\n",
    "dataset = dataset.drop(109)\n",
    "dataset = dataset.drop(111)\n",
    "dataset = dataset.drop(69)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we deleted rows just reset index after that delete title row\n",
    "dataset.reset_index()\n",
    "del dataset['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save last data\n",
    "dataset.to_csv('Data\\DataWithMusic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06d551a9c38e3c9226fb791b081d443165cdefd6b8907d1070492d8de0992181"
  },
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
