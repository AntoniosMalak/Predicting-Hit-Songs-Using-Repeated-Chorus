{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "- `path:` list of paths of chours.\n",
    "- `titles:` list of titles of songs.\n",
    "- `data:` a list contains data for each chours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('Data/chorusData.csv')\n",
    "paths = list(dataset['choruspath'])\n",
    "titles = list(dataset['Title'])\n",
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two methods to extract features.\n",
    "### First Method (statistics)\n",
    "    That include all statistics we extract from features (skew, min, max, std, mean, median, kurtosis)\n",
    "*`parameters`*\n",
    "- `list:` list of feature we extracted from chours.\n",
    "- `feature:` feature name shich we use with librosa.\n",
    "- `columns_name:` list of all features we extracted which is 518 stored them to use it as a columns of dataframe\n",
    "- `data:` data that contain 518 value which for every statistics for every feature. \n",
    "\n",
    "return data to collect all feature for it in second method....\n",
    "\n",
    "### Second Method (extract_features)\n",
    "    The main method of extract feature\n",
    "*`parameters`*\n",
    "- `audio_path:` path of chours we want to extract features from it.\n",
    "- `title:` title of chours\n",
    "\n",
    "return data and columns_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def statistics(list, feature, columns_name, data):\n",
    "    i = 0\n",
    "    for ele in list:\n",
    "        _skew = skew(ele)\n",
    "        columns_name.append(f'{feature}_kew_{i}')\n",
    "        min = np.min(ele)\n",
    "        columns_name.append(f'{feature}_min_{i}')\n",
    "        max = np.max(ele)\n",
    "        columns_name.append(f'{feature}_max_{i}')\n",
    "        std = np.std(ele)\n",
    "        columns_name.append(f'{feature}_std_{i}')\n",
    "        mean = np.mean(ele)\n",
    "        columns_name.append(f'{feature}_mean_{i}')\n",
    "        median = np.median(ele)\n",
    "        columns_name.append(f'{feature}_median_{i}')\n",
    "        _kurtosis = kurtosis(ele)\n",
    "        columns_name.append(f'{feature}_kurtosis_{i}')\n",
    "\n",
    "        i += 1\n",
    "        data.append(_skew) \n",
    "        data.append(min)\n",
    "        data.append(max) \n",
    "        data.append(std) \n",
    "        data.append(mean) \n",
    "        data.append(median) \n",
    "        data.append(_kurtosis)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def extract_features(audio_path, title):\n",
    "\n",
    "    data = []\n",
    "    columns_name = ['title']\n",
    "    data.append(title)\n",
    "    x , sr = librosa.load(audio_path)\n",
    "\n",
    "    chroma_stft = librosa.feature.chroma_stft(x, sr)\n",
    "    statistics(chroma_stft, 'chroma_stft', columns_name, data)\n",
    "\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(x, sr)\n",
    "    statistics(chroma_cqt, 'chroma_cqt', columns_name, data)\n",
    "\n",
    "    chroma_cens = librosa.feature.chroma_cens(x, sr)\n",
    "    statistics(chroma_cens, 'chroma_cens', columns_name, data)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(x, sr)\n",
    "    statistics(mfcc, 'mfcc', columns_name, data)\n",
    "    \n",
    "    rms = librosa.feature.rms(x, sr)\n",
    "    statistics(rms, 'rms', columns_name, data)\n",
    "\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(x , sr)\n",
    "    statistics(spectral_centroid, 'spectral_centroid', columns_name, data)\n",
    "\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(x , sr)\n",
    "    statistics(spectral_bandwidth, 'spectral_bandwidth', columns_name, data)\n",
    "\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(x , sr)\n",
    "    statistics(spectral_contrast, 'spectral_contrast', columns_name, data)\n",
    "    \n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(x , sr)\n",
    "    statistics(spectral_rolloff, 'spectral_rolloff', columns_name, data)\n",
    "\n",
    "    tonnetz = librosa.feature.tonnetz(x , sr)\n",
    "    statistics(tonnetz, 'tonnetz', columns_name, data)\n",
    "\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(x , sr)\n",
    "    statistics(zero_crossing_rate, 'zero_crossing_rate', columns_name, data)\n",
    "\n",
    "    return data, columns_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we extract features\n",
    "*`parameters`*\n",
    "- `i:` itrator to loop in paths.\n",
    "- `audio_path:` path of chorus.\n",
    "- `d:` data which returned from extract_features.\n",
    "- `cols:` colmuns_name which returned from extract_features.\n",
    "\n",
    "`NOTE` It took about 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(paths):\n",
    "    audio_path = paths[i]\n",
    "    d, cols = extract_features(audio_path, titles[i])\n",
    "    data.append(d)\n",
    "    print(f'The {i} song Done...')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first time we should convert data.\n",
    "newData = pd.DataFrame(data, columns=cols)\n",
    "newData.to_csv('Data/newData.csv')\n",
    "\n",
    "\n",
    "# Because I do it in several times, I use this code but I must use code above in the first time.\n",
    "# newData = pd.read_csv('Data/NewData.csv')\n",
    "# for row in data:\n",
    "#     newData = newData.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now add newData to dataset and clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's shape is (751, 523) if we deleted (Artist, Title, Label, Path, choruspath) columns it will be (751, 518 as mentioned in document)\n",
    "finaldata = pd.concat([dataset, newData], axis=1, join='inner')\n",
    "print(finaldata.shape)\n",
    "finaldata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtitles = list(newData['title'])\n",
    "lostdata = []  # list to Titles and titles with doesn't matches\n",
    "for i in range(len(titles)):\n",
    "    if titles[i] != newtitles[i]:\n",
    "        lostdata.append(titles[i])\n",
    "\n",
    "# to see if any lost data or not. if(just delete rows) else dataset is good\n",
    "lostdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete nan rows and data which titles doesn't match\n",
    "# dataset = dataset[dataset.Title.isin(lostdata) == False]\n",
    "# dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we deleted rows just reset index after that delete title row\n",
    "# dataset.reset_index()\n",
    "del finaldata['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save last data\n",
    "finaldata.to_csv('Data\\Final Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ab11c53d1d9a7b9c18284ee9fddbbfd900dbf67c14652a18f4e62b731fb1dbb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
