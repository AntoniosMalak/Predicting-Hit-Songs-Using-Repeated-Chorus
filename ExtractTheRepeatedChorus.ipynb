{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "- `paths:` list of paths of full songs.\n",
    "- `titles:` list of titles of songs.\n",
    "- `data:` list of dictionary that contains chorus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('Data/DataWithMusic.csv')\n",
    "paths = list(dataset['Path'])\n",
    "titles = list(dataset['Title'])\n",
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to extract chorus\n",
    "\n",
    "You have to download ffmpeg `<b>conda install -c conda-forge ffmpeg</b>` and use anconda.\n",
    "\n",
    "*`parametes:`*\n",
    "- `path:` path of full song.\n",
    "- `main:` main directory to save chorus.\n",
    "- `songname:` we take name of song from path.\n",
    "- `Newpath:` new path to save chorus in it.\n",
    "\n",
    "    return Newpath to save it in new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pychorus import find_and_output_chorus\n",
    "\n",
    "def extract_chorus(path, main):\n",
    "    songname = path.split('/', 2)[1].split('.')[0]\n",
    "    Newpath = main + '/' + songname + '.wav'\n",
    "    \n",
    "    chorus = find_and_output_chorus(path, Newpath, 15)\n",
    "    if chorus == None:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        return Newpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract chorus\n",
    "\n",
    "*Parameters*\n",
    "- `i:` iterator for looping in every path in paths.\n",
    "\n",
    "extract method when i from 0 to 376 is popular(Songs/RepeatedPopularChorus) and from 377 to end of data is unpopular(Unpopular/RepeatedUnpopularChorus).\n",
    "\n",
    "`Note:`\n",
    "\n",
    "*It took more than 6 hours*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(paths):\n",
    "    if i <= 376:\n",
    "        # Songs/RepeatedPopularChorus directory to collect all popular chours.\n",
    "        path = extract_chorus(paths[i], 'Songs/RepeatedPopularChorus') \n",
    "    else:\n",
    "        # Unpopular/RepeatedUnpopularChorus directory to collect all unpopular chours.\n",
    "        path = extract_chorus(paths[i], 'Unpopular/RepeatedUnpopularChorus') \n",
    "\n",
    "    data.append({'title': titles[i], 'choruspath': path})\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to dataframe and save it as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first time we should convert data.\n",
    "# newData = pd.DataFrame(data)  \n",
    "\n",
    "# Because I do it in several times, I use this code but I must use code above in the first time.\n",
    "newData = pd.read_csv('Data/NewData.csv')\n",
    "for row in data:\n",
    "    newData = newData.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if doubled choruspath in two songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = list(newData['choruspath'])\n",
    "lost = []\n",
    "for path in paths:\n",
    "    if len(newData[newData['choruspath']==path]) > 1:\n",
    "        lost.append(path)\n",
    "\n",
    "lost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data if some songs don't have chours or in lost list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = newData[newData.choruspath.isin(lost) == False]\n",
    "newData.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I did it because I made code in several days to save my work.\n",
    "newData.reset_index()\n",
    "newData.to_csv('Data/newData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now add newData to dataset and clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['choruspath'] = newData['choruspath'] # Add path column\n",
    "dataset['title'] = newData['title'] # Add title column with Title column in newData to check data\n",
    "newtitles = list(dataset['title'])  # to collect titles which we added\n",
    "titles = list(dataset['Title'])     # to coolect old Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lostdata = []  # list to Titles and titles with doesn't matches\n",
    "for i in range(len(titles)):\n",
    "    if titles[i] != newtitles[i]:\n",
    "        lostdata.append(titles[i])\n",
    "\n",
    "# to see if any lost data or not. if(just delete rows) else dataset is good\n",
    "lostdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete nan rows and data which titles doesn't match\n",
    "dataset = dataset[dataset.Title.isin(lostdata) == False]\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we deleted rows just reset index after that delete title row\n",
    "dataset.reset_index()\n",
    "del dataset['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save last data\n",
    "dataset.to_csv('Data\\chorusData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06d551a9c38e3c9226fb791b081d443165cdefd6b8907d1070492d8de0992181"
  },
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
